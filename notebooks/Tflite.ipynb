{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow_model_optimization.tfmot'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-147-94bbd289d03d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_model_optimization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtfmot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mquantize_annotate_layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow_model_optimization.tfmot'"
     ]
    }
   ],
   "source": [
    "from tensorflow_model_optimization.tfmot.quantization.keras import quantize_annotate_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import process_time, time\n",
    "import tempfile\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import tensorflow.keras.backend as K\n",
    "from statistics import mean\n",
    "\n",
    "def GetParametersNumber(model):\n",
    "    trainable_count = np.sum([K.count_params(w) for w in model.trainable_weights])\n",
    "    non_trainable_count = np.sum([K.count_params(w) for w in model.non_trainable_weights])\n",
    "    return trainable_count+non_trainable_count\n",
    "\n",
    "def GetSimpleModel(couche1=16,couche2=32,dense=512):\n",
    "    model = tf.keras.Sequential([\n",
    "      keras.layers.InputLayer(input_shape=(32, 32,3)),\n",
    "      keras.layers.Conv2D(couche1, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "#      keras.layers.LeakyReLU(alpha=0.2),\n",
    "      keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding=\"same\"),\n",
    "      keras.layers.Conv2D(couche2, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "      keras.layers.Flatten(),\n",
    "      keras.layers.Dense(dense, activation='relu'),\n",
    "      keras.layers.Dense(100),\n",
    "    ])\n",
    "    model._name='baseline'\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],)\n",
    "\n",
    "    model.fit(x_train, y_train, epochs=3,verbose=0)\n",
    "    return model\n",
    "\n",
    "def GetClusteredModel(model):\n",
    "    cluster_weights = tfmot.clustering.keras.cluster_weights\n",
    "    CentroidInitialization = tfmot.clustering.keras.CentroidInitialization\n",
    "\n",
    "    clustering_params = {\n",
    "      'number_of_clusters': 16,\n",
    "      'cluster_centroids_init': CentroidInitialization.LINEAR\n",
    "    }\n",
    "\n",
    "    # Cluster a whole model\n",
    "    clustered_model = cluster_weights(model, **clustering_params)\n",
    "\n",
    "    # Use smaller learning rate for fine-tuning clustered model\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
    "\n",
    "    clustered_model.compile(\n",
    "      loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "      optimizer=opt,\n",
    "      metrics=['accuracy'])\n",
    "\n",
    "    clustered_model.fit(x_train, y_train, epochs=3,verbose=0)\n",
    "    return clustered_model\n",
    "def GetQuantizedModel(model):\n",
    "    quantize_model = tfmot.quantization.keras.quantize_model\n",
    "\n",
    "    q_aware_model = quantize_model(model)\n",
    "\n",
    "    q_aware_model.compile(optimizer='adam',\n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    q_aware_model.fit(x_train, y_train, epochs=3,verbose=0)\n",
    "    return q_aware_model\n",
    "\n",
    "#ne fonctionne pas avec TFlite\n",
    "def GetPrunedModel(model):\n",
    "    prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
    "\n",
    "    batch_size = 1\n",
    "    epochs = 3\n",
    "    validation_split = 0.2\n",
    "\n",
    "    num_images = x_train.shape[0] * (1 - validation_split)\n",
    "    end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs\n",
    "\n",
    "    pruning_params = {\n",
    "          'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.50,\n",
    "                                                                   final_sparsity=0.80,\n",
    "                                                                   begin_step=0,\n",
    "                                                                   end_step=end_step)\n",
    "    }\n",
    "\n",
    "    model_for_pruning = prune_low_magnitude(model, **pruning_params)\n",
    "    model_for_pruning._name='pruned'\n",
    "    model_for_pruning.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "            loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "            metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],)\n",
    "    logdir = tempfile.mkdtemp()\n",
    "\n",
    "    callbacks = [\n",
    "      tfmot.sparsity.keras.UpdatePruningStep(),\n",
    "      tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
    "    ]\n",
    "\n",
    "    model_for_pruning.fit(x_train, y_train, epochs=3,verbose=0,callbacks=callbacks)\n",
    "    return model_for_pruning\n",
    "\n",
    "def GetTFLmodel(model):\n",
    "    tf_lite_converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    tf_lite_converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    tflite_model = tf_lite_converter.convert()\n",
    "    tflite_model_name = 'TFlite_post_quantModel8bit'\n",
    "    open(tflite_model_name, \"wb\").write(tflite_model)\n",
    "\n",
    "    interpreter = tf.lite.Interpreter(model_path = tflite_model_name)\n",
    "    interpreter.allocate_tensors()\n",
    "    input_details = interpreter.get_input_details() #1\n",
    "    output_details = interpreter.get_output_details() #16\n",
    "    return interpreter\n",
    "#pour les modèles classiques\n",
    "def GetTime(model_input,parameters):\n",
    "    nb_params=GetParametersNumber(model_input)\n",
    "    predictions=[]\n",
    "    temps_cpu=[]\n",
    "    temps_wall=[]\n",
    "    date=datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "    for k in range(nb_test):\n",
    "        start_cpu,start_wall=process_time(),time()\n",
    "        pred=model_input.predict(x_test[k].reshape(1,32,32,3))\n",
    "        stop_cpu,stop_wall=process_time(),time()\n",
    "        temps_cpu.append(stop_cpu-start_cpu)\n",
    "        temps_wall.append(stop_wall-start_wall)\n",
    "        predictions.append(np.argmax(pred))\n",
    "    accuracy=accuracy_score(np.array(predictions),y_test[0:nb_test][:,0])\n",
    "    return mean(temps_cpu),mean(temps_wall),accuracy,date,parameters,nb_params\n",
    "#pour les modèles TFlite\n",
    "def GetTFLtime(interpreter,parameters):\n",
    "    nb_params=None\n",
    "    date=datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "    pred = []\n",
    "    temps_cpu =[]\n",
    "    temps_wall=[]\n",
    "    for i in range(nb_test):  \n",
    "        start_cpu,start_wall= process_time(),time()\n",
    "\n",
    "        inp = X_test_numpy[i]\n",
    "        inp = inp.reshape(1 ,32, 32,3)\n",
    "        interpreter.set_tensor(0,inp )\n",
    "        interpreter.invoke()\n",
    "        tflite_model_predictions = interpreter.get_tensor(16)\n",
    "        prediction_classes = np.argmax(tflite_model_predictions, axis=1)\n",
    "        pred.append(prediction_classes[0])\n",
    "\n",
    "        stop_cpu,stop_wall=process_time(),time()\n",
    "\n",
    "        temps_wall.append(stop_wall-start_wall)\n",
    "        temps_cpu.append(stop_cpu-start_cpu)\n",
    "    accuracy=accuracy_score(np.array(pred),y_test[0:nb_test][:,0])\n",
    "    return mean(temps_cpu),mean(temps_wall),accuracy,date,parameters,nb_params\n",
    "#pour enregistrer les infos dans result\n",
    "def SendData(result,time_cpu,time_wall,accuracy,date,parameters,nb_params):\n",
    "    result=result.append({'Modèle':model_name,'CPU + Sys time':time_cpu,'Wall Time':time_wall,'Précision':accuracy,'Date':date,'Méthode':method_name,'Paramètres':parameters,'Nb(paramètres)':nb_params}, ignore_index=True)\n",
    "    return result\n",
    "\n",
    "nb_test=1000\n",
    "couche1=64\n",
    "couche2=128\n",
    "dense=512\n",
    "model_name='CNN'\n",
    "method_name='TFLite'\n",
    "\n",
    "cifar100 = tf.keras.datasets.cifar100\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "X_test_numpy = np.array(x_test, dtype=np.float32)\n",
    "y_test_numpy =np.array(y_test, dtype=np.float32)\n",
    "\n",
    "result=pd.DataFrame(columns=['Modèle','Nb(paramètres)','Date','Méthode','Paramètres','CPU + Sys time','Précision','Wall Time'])\n",
    "\n",
    "model=GetSimpleModel()\n",
    "#model_pruned=GetPrunedModel(model) #ne fonctionne pas avec TFlite\n",
    "model_copy = keras.models.clone_model(model)\n",
    "model_clustered=GetClusteredModel(model_copy)\n",
    "model_copy = keras.models.clone_model(model)\n",
    "model_quantized=GetQuantizedModel(model_copy)\n",
    "\n",
    "names=['Baseline','Weight_Clustering','Quantized']\n",
    "models=[model,model_clustered,model_quantized]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_cpu,time_wall,accuracy,date,parameters,nb_params=GetTime(models[0],names[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.348"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetSimpleModel(couche1=16,couche2=32,dense=512):\n",
    "    model = tf.keras.Sequential([\n",
    "      keras.layers.InputLayer(input_shape=(32, 32,3)),\n",
    "      keras.layers.Conv2D(couche1, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "      quantize_annotate_layer(keras.layers.LeakyReLU(alpha=0.2)),\n",
    "      keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding=\"same\"),\n",
    "      keras.layers.Conv2D(couche2, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "      keras.layers.Flatten(),\n",
    "      keras.layers.Dense(dense, activation='relu'),\n",
    "      keras.layers.Dense(100),\n",
    "    ])\n",
    "    model._name='baseline'\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],)\n",
    "\n",
    "    model.fit(x_train, y_train, epochs=3,verbose=0)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'quantize_annotate_layer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-145-22dd71697aa1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mGetSimpleModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-144-314a0ae1abf8>\u001b[0m in \u001b[0;36mGetSimpleModel\u001b[0;34m(couche1, couche2, dense)\u001b[0m\n\u001b[1;32m      3\u001b[0m       \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInputLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m       \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcouche1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"same\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m       \u001b[0mquantize_annotate_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLeakyReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m       \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"same\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m       \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcouche2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"same\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'quantize_annotate_layer' is not defined"
     ]
    }
   ],
   "source": [
    "model=GetSimpleModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Layer leaky_re_lu_19:<class 'tensorflow.python.keras.layers.advanced_activations.LeakyReLU'> is not supported. You can quantize this layer by passing a `tfmot.quantization.keras.QuantizeConfig` instance to the `quantize_annotate_layer` API.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-143-4fe2be9b2fe7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_quantized\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mGetQuantizedModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-75-5cea01a4f3c3>\u001b[0m in \u001b[0;36mGetQuantizedModel\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mquantize_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfmot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantize_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m     \u001b[0mq_aware_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquantize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     q_aware_model.compile(optimizer='adam',\n",
      "\u001b[0;32m~/deeplearning-cpu-optimization/venv/lib/python3.6/site-packages/tensorflow_model_optimization/python/core/quantization/keras/quantize.py\u001b[0m in \u001b[0;36mquantize_model\u001b[0;34m(to_quantize)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mannotated_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquantize_annotate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_quantize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mquantize_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mannotated_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/deeplearning-cpu-optimization/venv/lib/python3.6/site-packages/tensorflow_model_optimization/python/core/quantization/keras/quantize.py\u001b[0m in \u001b[0;36mquantize_apply\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m   return keras.models.clone_model(\n\u001b[0;32m--> 421\u001b[0;31m       transformed_model, input_tensors=None, clone_function=_quantize)\n\u001b[0m",
      "\u001b[0;32m~/deeplearning-cpu-optimization/venv/lib/python3.6/site-packages/tensorflow/python/keras/models.py\u001b[0m in \u001b[0;36mclone_model\u001b[0;34m(model, input_tensors, clone_function)\u001b[0m\n\u001b[1;32m    422\u001b[0m   \"\"\"\n\u001b[1;32m    423\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mclone_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m     \u001b[0mclone_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_clone_layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/deeplearning-cpu-optimization/venv/lib/python3.6/site-packages/tensorflow/python/keras/models.py\u001b[0m in \u001b[0;36m_clone_sequential_model\u001b[0;34m(model, input_tensors, layer_fn)\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mInputLayer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0minput_tensors\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m       \u001b[0;31m# If input tensors are provided, the original model's InputLayer is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m       \u001b[0;31m# overwritten with a different InputLayer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m     cloned_layer = (\n",
      "\u001b[0;32m~/deeplearning-cpu-optimization/venv/lib/python3.6/site-packages/tensorflow_model_optimization/python/core/quantization/keras/quantize.py\u001b[0m in \u001b[0;36m_quantize\u001b[0;34m(layer)\u001b[0m\n\u001b[1;32m    370\u001b[0m       raise RuntimeError(\n\u001b[1;32m    371\u001b[0m           error_msg.format(layer.name, layer.__class__,\n\u001b[0;32m--> 372\u001b[0;31m                            quantize_registry.__class__))\n\u001b[0m\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m     \u001b[0;31m# `QuantizeWrapper` does not copy any additional layer params from\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Layer leaky_re_lu_19:<class 'tensorflow.python.keras.layers.advanced_activations.LeakyReLU'> is not supported. You can quantize this layer by passing a `tfmot.quantization.keras.QuantizeConfig` instance to the `quantize_annotate_layer` API."
     ]
    }
   ],
   "source": [
    "model_quantized=GetQuantizedModel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "intepreter=GetTFLmodel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_cpu,time_wall,accuracy,date,parameters,nb_params=GetTFLtime(intepreter,names[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.359"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(len(names)):\n",
    "    time_cpu,time_wall,accuracy,date,parameters,nb_params=GetTime(models[k],names[k])\n",
    "    result=SendData(result,time_cpu,time_wall,accuracy,date,parameters,nb_params)\n",
    "\n",
    "names=['TFlite(baseline)','TFlite(weight clustering)','TFlite(quantization)']\n",
    "for k in range(len(names)):\n",
    "    intepreter=GetTFLmodel(models[k])\n",
    "    time_cpu,time_wall,accuracy,date,parameters,nb_params=GetTFLtime(intepreter,names[k])\n",
    "    result=SendData(result,time_cpu,time_wall,accuracy,date,parameters,nb_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlcpu",
   "language": "python",
   "name": "dlcpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
