{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IqR2PQG4ZaZ0",
    "outputId": "ba29e8a0-67bd-4da1-e05f-4c46fc7b1db6"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YRt3DBzC8O8m"
   },
   "source": [
    "## Model With less Bit first approach "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iLtGD2YTmCyM"
   },
   "source": [
    "Today, most models use the float32 dtype, which takes 32 bits of memory. However, there are two lower-precision dtypes, float16 and bfloat16, each which take 16 bits of memory instead. Modern accelerators can run operations faster in the 16-bit dtypes, as they have specialized hardware to run 16-bit computations and 16-bit dtypes can be read from memory faster.In case of CPU float 32 is the faster approach :) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TestInferenceOfBits_Dense(bits_number):\n",
    "    model = tf.keras.models.Sequential([\n",
    "      tf.keras.layers.Flatten(input_shape=(28,28)),\n",
    "      tf.keras.layers.Dense(64,activation='relu', dtype=bits_number),\n",
    "      tf.keras.layers.Dense(64,activation='relu', dtype=bits_number),\n",
    "      tf.keras.layers.Dense(10,activation='softmax', dtype=bits_number)\n",
    "    ])\n",
    "    model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "    # changing data type and making the pixel value normalize (1-0)\n",
    "    x_train = x_train.astype(bits_number) /255.\n",
    "    x_test = x_test.astype(bits_number) /255.\n",
    "    \n",
    "    history = model.fit(x_train, y_train,\n",
    "                    batch_size=1000,\n",
    "                    epochs=5,\n",
    "                    validation_split=0.2,\n",
    "                   verbose=0)\n",
    "    start=time.time()\n",
    "    model.predict(x_test)\n",
    "    stop=time.time()\n",
    "    return stop-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2786731719970703\n",
      "0.35553526878356934\n",
      "0.2551863193511963\n",
      "3.496459722518921\n"
     ]
    }
   ],
   "source": [
    "print(TestInferenceOfBits_Dense(None))\n",
    "print(TestInferenceOfBits_Dense('float64'))\n",
    "print(TestInferenceOfBits_Dense('float32'))\n",
    "print(TestInferenceOfBits_Dense('float16'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_value=tf.keras.backend.floatx()\n",
    "\n",
    "def TestInferenceOfBits(bits_number):\n",
    "    if bits_number==None:\n",
    "        tf.keras.backend.set_floatx(default_value)\n",
    "    else :\n",
    "        tf.keras.backend.set_floatx(bits_number)\n",
    "    model = tf.keras.models.Sequential(\n",
    "      [\n",
    "        keras.Input(shape=(28, 28, 1)),\n",
    "        layers.Conv2D(64, (3, 3), strides=(2, 2), padding=\"same\", dtype=bits_number),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding=\"same\", dtype=bits_number),\n",
    "        layers.Conv2D(128, (3, 3), strides=(2, 2), padding=\"same\", dtype=bits_number),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(10, dtype=bits_number),\n",
    "    ]\n",
    "    )\n",
    "\n",
    "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "    # changing data type and making the pixel value normalize (1-0)\n",
    "    x_train = np.reshape(x_train, (-1, 28, 28, 1))\n",
    "    x_train = x_train.astype(bits_number) /255.\n",
    "    x_test = np.reshape(x_test, (-1, 28, 28, 1))\n",
    "    x_test = x_test.astype(bits_number) /255.\n",
    "    \n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(),\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    "        )\n",
    "\n",
    "    # Train and evaluate teacher on data.\n",
    "    model.fit(x_train, y_train, epochs=1,batch_size=10)\n",
    "\n",
    "    start=time.time()\n",
    "    model.predict(x_test)\n",
    "    stop=time.time()\n",
    "    return stop-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 21s 4ms/step - loss: 0.1421 - sparse_categorical_accuracy: 0.9562\n",
      "0.5577178001403809\n",
      "6000/6000 [==============================] - 27s 5ms/step - loss: 0.1447 - sparse_categorical_accuracy: 0.9553\n",
      "1.1191236972808838\n",
      "6000/6000 [==============================] - 21s 4ms/step - loss: 0.1425 - sparse_categorical_accuracy: 0.9569\n",
      "0.941617488861084\n",
      "6000/6000 [==============================] - 1057s 176ms/step - loss: nan - sparse_categorical_accuracy: 0.1414\n",
      "3.0806760787963867\n"
     ]
    }
   ],
   "source": [
    "print(TestInferenceOfBits(None))\n",
    "print(TestInferenceOfBits('float64'))\n",
    "print(TestInferenceOfBits('float32'))\n",
    "print(TestInferenceOfBits('float16'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fM1oI-IViUVm"
   },
   "source": [
    "Mixed precission : Mixed precision is the use of both 16-bit and 32-bit floating-point types in a model during training to make it run faster and use less memory. By keeping certain parts of the model in the 32-bit types for numeric stability, the model will have a lower step time and train equally as well in terms of the evaluation metrics such as accuracy. This guide describes how to use the Keras mixed precision API to speed up your models. Using this API can improve performance by more than 3 times on modern GPUs and 60% on TPUs.\n",
    "\n",
    "[Here](https://www.tensorflow.org/guide/mixed_precision) ypu will find all other details for mixed precision "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Cooding with less bit MNIST.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
