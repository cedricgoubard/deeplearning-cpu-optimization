{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T15:48:48.543123Z",
     "start_time": "2021-04-13T15:48:48.536393Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "import tempfile\n",
    "import zipfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'ConfigProto'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-d49cdfb190f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m config = tf.ConfigProto(\n\u001b[0m\u001b[1;32m      2\u001b[0m         \u001b[0mdevice_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'GPU'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     )\n\u001b[1;32m      4\u001b[0m \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'ConfigProto'"
     ]
    }
   ],
   "source": [
    "config = tf.ConfigProto(\n",
    "        device_count = {'GPU': 0}\n",
    "    )\n",
    "sess = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST dataset\n",
    "mnist = keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Normalize the input image so that each pixel value is between 0 to 1.\n",
    "# x_train = x_train / 255.0\n",
    "# x_test  = x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=x_train/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-ea49ee0df236>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mFit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-ea49ee0df236>\u001b[0m in \u001b[0;36mFit\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     22\u001b[0m               metrics=['accuracy'])\n\u001b[1;32m     23\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mFit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Load MNIST dataset\n",
    "mnist = keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Normalize the input image so that each pixel value is between 0 to 1.\n",
    "x_train = x_train / 255.0\n",
    "x_test  = x_test / 255.0\n",
    "\n",
    "# Define the model architecture.\n",
    "model = keras.Sequential([   \n",
    "        tf.keras.Input(shape=(28, 28, 1)),\n",
    "        tf.keras.layers.Conv2D(16, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "        tf.keras.layers.LeakyReLU(alpha=0.2),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding=\"same\"),\n",
    "        tf.keras.layers.Conv2D(32, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(10)])\n",
    "\n",
    "# Train the digit classification model\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "def Fit(model):\n",
    "    model.fit(x_train, y_train, epochs=3,verbose=0)\n",
    "    return model\n",
    "\n",
    "Fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline test accuracy: 0.9783999919891357\n",
      "Saving model to:  /tmp/tmpsxf23w3d.h5\n"
     ]
    }
   ],
   "source": [
    "_, baseline_model_accuracy = model.evaluate(\n",
    "    test_images, test_labels, verbose=0)\n",
    "\n",
    "print('Baseline test accuracy:', baseline_model_accuracy)\n",
    "\n",
    "_, keras_file = tempfile.mkstemp('.h5')\n",
    "print('Saving model to: ', keras_file)\n",
    "tf.keras.models.save_model(model, keras_file, include_optimizer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "cluster_reshape_1 (ClusterWe (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "cluster_conv2d_1 (ClusterWei (None, 26, 26, 12)        136       \n",
      "_________________________________________________________________\n",
      "cluster_max_pooling2d_1 (Clu (None, 13, 13, 12)        0         \n",
      "_________________________________________________________________\n",
      "cluster_flatten_1 (ClusterWe (None, 2028)              0         \n",
      "_________________________________________________________________\n",
      "cluster_dense_1 (ClusterWeig (None, 10)                20306     \n",
      "=================================================================\n",
      "Total params: 20,442\n",
      "Trainable params: 54\n",
      "Non-trainable params: 20,388\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "cluster_weights = tfmot.clustering.keras.cluster_weights\n",
    "CentroidInitialization = tfmot.clustering.keras.CentroidInitialization\n",
    "\n",
    "clustering_params = {\n",
    "  'number_of_clusters': 16,\n",
    "  'cluster_centroids_init': CentroidInitialization.LINEAR\n",
    "}\n",
    "\n",
    "# Cluster a whole model\n",
    "clustered_model = cluster_weights(model, **clustering_params)\n",
    "\n",
    "# Use smaller learning rate for fine-tuning clustered model\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
    "\n",
    "clustered_model.compile(\n",
    "  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "  optimizer=opt,\n",
    "  metrics=['accuracy'])\n",
    "\n",
    "clustered_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108/108 [==============================] - 2s 20ms/step - loss: 0.0603 - accuracy: 0.9794 - val_loss: 0.0874 - val_accuracy: 0.9735\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9db06b3a90>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fine-tune model\n",
    "clustered_model.fit(\n",
    "  train_images,\n",
    "  train_labels,\n",
    "  batch_size=500,\n",
    "  epochs=1,\n",
    "  validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving clustered model to:  /tmp/tmpinwkmqjf.h5\n"
     ]
    }
   ],
   "source": [
    "final_model = tfmot.clustering.keras.strip_clustering(clustered_model)\n",
    "\n",
    "_, clustered_keras_file = tempfile.mkstemp('.h5')\n",
    "print('Saving clustered model to: ', clustered_keras_file)\n",
    "tf.keras.models.save_model(final_model, clustered_keras_file, \n",
    "                           include_optimizer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved clustered TFLite model to: /tmp/clustered_mnist.tflite\n"
     ]
    }
   ],
   "source": [
    "clustered_tflite_file = '/tmp/clustered_mnist.tflite'\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(final_model)\n",
    "tflite_clustered_model = converter.convert()\n",
    "with open(clustered_tflite_file, 'wb') as f:\n",
    "  f.write(tflite_clustered_model)\n",
    "print('Saved clustered TFLite model to:', clustered_tflite_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_model_optimization as tfmot\n",
    "def GetClusteredModel(model):\n",
    "    cluster_weights = tfmot.clustering.keras.cluster_weights\n",
    "    CentroidInitialization = tfmot.clustering.keras.CentroidInitialization\n",
    "\n",
    "    clustering_params = {\n",
    "      'number_of_clusters': 16,\n",
    "      'cluster_centroids_init': CentroidInitialization.LINEAR\n",
    "    }\n",
    "\n",
    "    # Cluster a whole model\n",
    "    clustered_model = cluster_weights(model, **clustering_params)\n",
    "\n",
    "    # Use smaller learning rate for fine-tuning clustered model\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
    "\n",
    "    clustered_model.compile(\n",
    "      loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "      optimizer=opt,\n",
    "      metrics=['accuracy'])\n",
    "\n",
    "    clustered_model.fit(x_train, y_train, epochs=3,verbose=0)\n",
    "    return clustered_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetPrunedModel(model):\n",
    "    cluster_weights = tfmot.clustering.keras.cluster_weights\n",
    "    CentroidInitialization = tfmot.clustering.keras.CentroidInitialization\n",
    "\n",
    "    clustering_params = {\n",
    "      'number_of_clusters': 16,\n",
    "      'cluster_centroids_init': CentroidInitialization.LINEAR\n",
    "    }\n",
    "\n",
    "    clustered_model = cluster_weights(model, **clustering_params)\n",
    "\n",
    "    clustered_model._name='weight clustering'\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
    "    \n",
    "    clustered_model.compile(\n",
    "      loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "      optimizer=opt,\n",
    "      metrics=['accuracy'])\n",
    "    logdir = tempfile.mkdtemp()\n",
    "\n",
    "    callbacks = [\n",
    "      tfmot.sparsity.keras.UpdatePruningStep(),\n",
    "      tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
    "    ]\n",
    "\n",
    "    model_for_pruning.fit(x_train, y_train, epochs=3,verbose=0,callbacks=callbacks)\n",
    "    return model_for_pruning\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf3-env",
   "language": "python",
   "name": "tf3-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
