{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T10:25:07.586163Z",
     "start_time": "2021-04-14T10:25:07.579880Z"
    }
   },
   "outputs": [],
   "source": [
    "from time import process_time\n",
    "import statistics\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow.keras.backend as K\n",
    "from sklearn.metrics import accuracy_score\n",
    "from datetime import datetime\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T09:11:19.676718Z",
     "start_time": "2021-04-14T09:11:19.667855Z"
    }
   },
   "outputs": [],
   "source": [
    "import signal\n",
    "\n",
    "class timeout:\n",
    "    def __init__(self, seconds=1, error_message='Timeout'):\n",
    "        self.seconds = seconds\n",
    "        self.error_message = error_message\n",
    "    def handle_timeout(self, signum, frame):\n",
    "        raise TimeoutError(self.error_message)\n",
    "    def __enter__(self):\n",
    "        signal.signal(signal.SIGALRM, self.handle_timeout)\n",
    "        signal.alarm(self.seconds)\n",
    "    def __exit__(self, type, value, traceback):\n",
    "        signal.alarm(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T10:39:29.182965Z",
     "start_time": "2021-04-14T10:39:29.178370Z"
    }
   },
   "outputs": [],
   "source": [
    "default_value=tf.keras.backend.floatx()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T11:33:25.087590Z",
     "start_time": "2021-04-14T11:33:25.082090Z"
    }
   },
   "outputs": [],
   "source": [
    "layers_types=['float32','float64']\n",
    "inputs_types=['int8','int16','int32','float16','float32','float64']\n",
    "method_name='Format des inputs/layers'\n",
    "model_name='CNN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle:  CNN Input:  int8 & Layers:  float32 --> time :  timeout --> accuracy :  0.0984\n",
      "Modèle:  CNN Input:  int8 & Layers:  float64 --> time :  timeout --> accuracy :  0.0908\n",
      "Modèle:  CNN Input:  int16 & Layers:  float32 --> time :  timeout --> accuracy :  0.1893\n",
      "Modèle:  CNN Input:  int16 & Layers:  float64 --> time :  timeout --> accuracy :  0.1986\n",
      "Modèle:  CNN Input:  int32 & Layers:  float32 --> time :  timeout --> accuracy :  0.1554\n",
      "Modèle:  CNN Input:  int32 & Layers:  float64 --> time :  timeout --> accuracy :  0.1786\n",
      "Modèle:  CNN Input:  float16 & Layers:  float32 --> time :  timeout --> accuracy :  0.2817\n",
      "Modèle:  CNN Input:  float16 & Layers:  float64 --> time :  timeout --> accuracy :  0.1631\n",
      "Modèle:  CNN Input:  float32 & Layers:  float32 --> time :  timeout --> accuracy :  0.2593\n",
      "Modèle:  CNN Input:  float32 & Layers:  float64 --> time :  timeout --> accuracy :  0.1079\n",
      "Modèle:  CNN Input:  float64 & Layers:  float32 --> time :  9.037169096709986 --> accuracy :  0.1042\n",
      "Modèle:  CNN Input:  float64 & Layers:  float64 --> time :  timeout --> accuracy :  0.2066\n"
     ]
    }
   ],
   "source": [
    "result=pd.DataFrame(columns=['Modèle','Nb(paramètres)','Date','Méthode','Paramètres','CPU + Sys time','Précision'])\n",
    "for inputs_type in inputs_types:\n",
    "    for layers_type in layers_types:\n",
    "        time,accuracy,date,parameters,nb_params=GetTime(model_name,inputs_type,layers_type,iteration=100,time_out=120)\n",
    "        result=result.append({'Modèle':model_name,'CPU + Sys time':time,'Précision':accuracy,'Date':date,'Méthode':method_name,'Paramètres':parameters,'Nb(paramètres)':nb_params}, ignore_index=True)\n",
    "        print('Modèle: ',model_name,'Input: ',inputs_type, '&', 'Layers: ',layers_type,'--> time : ',time,'--> accuracy : ',accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train = np.reshape(x_train, (-1, 28, 28, 1))\n",
    "x_test = np.reshape(x_test, (-1, 28, 28, 1))\n",
    "\n",
    "x_train = x_train.astype(\"float32\")\n",
    "x_train = np.reshape(x_train, (-1, 28, 28, 1))\n",
    "\n",
    "x_test = x_test.astype(\"float32\")\n",
    "x_test = np.reshape(x_test, (-1, 28, 28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_type='float32'\n",
    "tf.keras.backend.set_floatx(layers_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.Input(shape=(28, 28, 1)),\n",
    "        tf.keras.layers.Conv2D(16, (3, 3), strides=(2, 2), padding=\"same\",dtype='layers_type'),\n",
    "        tf.keras.layers.LeakyReLU(alpha=0.2),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding=\"same\",dtype='layers_type'),\n",
    "        tf.keras.layers.Conv2D(32, (3, 3), strides=(2, 2), padding=\"same\",dtype='layers_type'),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(10,dtype='layers_type'),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.7728 - sparse_categorical_accuracy: 0.9248\n",
      "Epoch 2/3\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1479 - sparse_categorical_accuracy: 0.9628\n",
      "Epoch 3/3\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1188 - sparse_categorical_accuracy: 0.9672\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1185 - sparse_categorical_accuracy: 0.9673\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.11853490024805069, 0.9672999978065491]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    ")\n",
    "\n",
    "# Train and evaluate student trained from scratch.\n",
    "model.fit(x_train, y_train, epochs=3)\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(np.argmax(y_pred,1),y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict(x_test)\n",
    "\n",
    "accuracys.append(accuracy_score(np.argmax(y_pred,1),y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Data cardinality is ambiguous:\n  x sizes: 60000\n  y sizes: 10000\nPlease provide data which shares the same first dimension.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-3902a7f7185a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1354\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1355\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1356\u001b[0;31m             steps_per_execution=self._steps_per_execution)\n\u001b[0m\u001b[1;32m   1357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[1;32m   1115\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1117\u001b[0;31m         model=model)\n\u001b[0m\u001b[1;32m   1118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    280\u001b[0m             label, \", \".join(str(i.shape[0]) for i in nest.flatten(data)))\n\u001b[1;32m    281\u001b[0m       \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"Please provide data which shares the same first dimension.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m     \u001b[0mnum_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 60000\n  y sizes: 10000\nPlease provide data which shares the same first dimension."
     ]
    }
   ],
   "source": [
    "model.evaluate(x_train,x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T10:53:00.087300Z",
     "start_time": "2021-04-14T10:53:00.071320Z"
    }
   },
   "outputs": [],
   "source": [
    "def GetModel(layers_type=None,model_name='MLP'):\n",
    "    tf.keras.backend.set_floatx(layers_type)\n",
    "    if model_name=='MLP':\n",
    "        model = tf.keras.models.Sequential([\n",
    "              tf.keras.layers.Flatten(input_shape=(28,28,1)),\n",
    "              tf.keras.layers.Dense(64,activation='relu', dtype=layers_type),\n",
    "              tf.keras.layers.Dense(64,activation='relu', dtype=layers_type),\n",
    "              tf.keras.layers.Dense(10,activation='softmax', dtype=layers_type)\n",
    "            ])\n",
    "    elif model_name=='CNN':\n",
    "        model = tf.keras.Sequential([\n",
    "        tf.keras.Input(shape=(28, 28, 1),dtype=layers_type),\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), strides=(2, 2), padding=\"same\",dtype=layers_type),\n",
    "        tf.keras.layers.LeakyReLU(alpha=0.2),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding=\"same\",dtype=layers_type),\n",
    "        tf.keras.layers.Conv2D(128, (3, 3), strides=(2, 2), padding=\"same\",dtype=layers_type),\n",
    "        tf.keras.layers.Flatten(dtype=layers_type),\n",
    "        tf.keras.layers.Dense(10,dtype=layers_type)])\n",
    "    else:\n",
    "        print('This model doesn\\'t exist.')\n",
    "    return model \n",
    "\n",
    "def GetParametersNumber(model):\n",
    "    trainable_count = np.sum([K.count_params(w) for w in model.trainable_weights])\n",
    "    non_trainable_count = np.sum([K.count_params(w) for w in model.non_trainable_weights])\n",
    "    return trainable_count+non_trainable_count\n",
    "\n",
    "def GetTime(model_name,inputs_type,layers_type,iteration,time_out):\n",
    "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "    x_train = np.reshape(x_train, (-1, 28, 28, 1))\n",
    "    x_test = np.reshape(x_test, (-1, 28, 28, 1))\n",
    "    \n",
    "    x_train_type = x_train.astype(inputs_type)\n",
    "    x_test_type = x_test.astype(inputs_type)\n",
    "    \n",
    "    model=GetModel(layers_type=layers_type,model_name=model_name)\n",
    "\n",
    "    model.compile(loss='sparse_categorical_crossentropy',\n",
    "                 optimizer=tf.keras.optimizers.RMSprop(),\n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "    model.fit(x_train, y_train,\n",
    "                 batch_size=1000,\n",
    "                 epochs=1,\n",
    "                 validation_split=0.2,\n",
    "                 verbose=0)\n",
    "    \n",
    "    nb_params=GetParametersNumber(model)\n",
    "    date=datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "    parameters={'inputs_type':inputs_type,'layers_type':layers_type}\n",
    "    temps=[]\n",
    "    accuracys=[]\n",
    "    with timeout(seconds=time_out):\n",
    "        try:\n",
    "            for k in range(iteration):\n",
    "                start=process_time()\n",
    "                y_pred=model.predict(x_test_type)\n",
    "                stop=process_time()\n",
    "                temps.append(stop-start)\n",
    "                accuracys.append(accuracy_score(np.argmax(y_pred,1),y_test))\n",
    "                tf.keras.backend.set_floatx(default_value)\n",
    "            return statistics.mean(temps),statistics.mean(accuracys),date,parameters,nb_params\n",
    "        except Exception as e:\n",
    "            tf.keras.backend.set_floatx(default_value)\n",
    "            return 'timeout', statistics.mean(accuracys),date,parameters,nb_params"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Cooding with less bit MNIST.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
